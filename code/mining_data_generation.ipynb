{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# WA Mining Operations Data Generator\n",
        "## Western Australia Mining Performance Dashboard - Project #3\n",
        "\n",
        "**Author:** Flavio Coltellacci  \n",
        "**Date:** January 2026  \n",
        "**Purpose:** Generate realistic synthetic dataset for mining operations BI dashboard\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook generates a synthetic dataset representing 12 months (2025) of mining operations data across 4 Western Australian mine sites.\n",
        "\n",
        "**Data Generated:**\n",
        "1. **mine_sites.csv** - Master data for 5 mine sites (4 operational + 1 care & maintenance)\n",
        "2. **daily_production.csv** - 1,825 daily production records (365 days Ã— 5 sites)\n",
        "3. **equipment_performance.csv** - ~8,400 equipment records (365 days Ã— 23 units)\n",
        "4. **safety_incidents.csv** - ~360 safety incidents (realistic frequency)\n",
        "5. **daily_costs.csv** - 1,825 cost records (by site and date)\n",
        "6. **safety_metrics_summary.csv** - TRIFR/LTIFR calculations by site\n",
        "\n",
        "**Industry Research:**\n",
        "All parameters based on 2025 Western Australian mining industry benchmarks:\n",
        "- Department of Mines, Industry Regulation and Safety (DMIRS) WA\n",
        "- WorkSafe WA statistics\n",
        "- Major mining companies' operational reports\n",
        "\n",
        "**Key Features:**\n",
        "- Realistic operational variance (Â±5-10% from targets)\n",
        "- Seasonal impacts (Jan-Mar cyclone season: 15-20% production loss in Pilbara)\n",
        "- Quarterly maintenance shutdowns (2-3 days)\n",
        "- Random equipment failures based on MTBF\n",
        "- Industry-accurate KPIs: TRIFR, OEE, AISC, recovery rates\n",
        "\n",
        "---\n",
        "\n",
        "## Technologies Used\n",
        "- Python 3.10+\n",
        "- Pandas (data manipulation)\n",
        "- NumPy (random generation)\n",
        "- Datetime (date handling)\n",
        "\n",
        "---\n",
        "\n",
        "## How to Use\n",
        "1. Run all cells sequentially\n",
        "2. Download generated CSV files from Colab\n",
        "3. Import into SQLite database\n",
        "4. Use for analysis and visualization\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "D6DxY8vqFDZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# WA MINING OPERATIONS DATA GENERATOR\n",
        "# Project: Mining Operations Performance Dashboard\n",
        "# Date: December 2025\n",
        "# =====================================================\n",
        "\n",
        "# Install required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"WA MINING OPERATIONS DATA GENERATOR\")\n",
        "print(\"Generating realistic 2025 mining data for 5 WA mine sites\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# =====================================================\n",
        "# DATASET 1: MINE SITES MASTER DATA\n",
        "# =====================================================\n",
        "\n",
        "print(\"\\n[1/5] Generating Mine Sites Master Data...\")\n",
        "\n",
        "mine_sites = {\n",
        "    'site_id': ['IRON001', 'GOLD001', 'LITH001', 'COPP001', 'NICK001'],\n",
        "    'site_name': [\n",
        "        'Iron Ridge Mine',\n",
        "        'Golden Valley Mine',\n",
        "        'Lithium Creek Mine',\n",
        "        'Copper Hills Mine',\n",
        "        'Nickel Point Mine'\n",
        "    ],\n",
        "    'commodity': ['Iron Ore', 'Gold', 'Lithium', 'Copper', 'Nickel'],\n",
        "    'region': ['Pilbara', 'Goldfields', 'Pilbara', 'Mid West', 'Kambalda'],\n",
        "    'latitude': [-22.5847, -30.7458, -21.8956, -28.4521, -31.2089],\n",
        "    'longitude': [117.8853, 121.4656, 118.7234, 117.1234, 121.6447],\n",
        "    'mine_type': ['Open Pit', 'Open Pit + Underground', 'Open Pit', 'Underground', 'Underground'],\n",
        "    'status': ['Operational', 'Operational', 'Operational', 'Operational', 'Care & Maintenance'],\n",
        "    'annual_target_tonnes': [50000000, 13000000, 700000, 20000, 0],  # Iron in tonnes, Gold in tonnes ore, Lithium in concentrate, Copper in metal\n",
        "    'daily_target_tonnes': [137000, 35600, 1920, 55, 0],\n",
        "    'target_recovery_rate': [98.0, 91.0, 70.0, 88.0, 0.0],  # %\n",
        "    'target_head_grade': [62.0, 1.2, 1.3, 2.8, 0.0],  # Fe%, g/t Au, Li2O%, Cu%\n",
        "    'workforce_count': [850, 1200, 450, 280, 25],  # 25 for care & maintenance\n",
        "    'automation_level': ['High', 'Medium', 'Medium', 'Low', 'N/A'],  # Autonomous equipment %\n",
        "    'cost_per_unit_target': [27.0, 2500.0, 640.0, 1.85, 0.0],  # Iron $/t, Gold $/oz, Lithium $/t, Copper $/lb (in AUD)\n",
        "    'operating_since': ['2023-06-01', '1989-03-15', '2021-11-01', '2007-04-20', '2018-02-10']\n",
        "}\n",
        "\n",
        "df_sites = pd.DataFrame(mine_sites)\n",
        "\n",
        "print(f\"âœ“ Created mine sites data: {len(df_sites)} sites\")\n",
        "print(df_sites[['site_id', 'site_name', 'commodity', 'status']].to_string(index=False))\n",
        "\n",
        "# =====================================================\n",
        "# DATASET 2: DAILY PRODUCTION DATA (365 days Ã— 5 sites)\n",
        "# =====================================================\n",
        "\n",
        "print(\"\\n[2/5] Generating Daily Production Data (365 days)...\")\n",
        "\n",
        "start_date = datetime(2025, 1, 1)\n",
        "end_date = datetime(2025, 12, 31)\n",
        "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
        "\n",
        "production_records = []\n",
        "\n",
        "for site in df_sites.itertuples():\n",
        "    site_id = site.site_id\n",
        "    site_name = site.site_name\n",
        "    commodity = site.commodity\n",
        "    daily_target = site.daily_target_tonnes\n",
        "    target_grade = site.target_head_grade\n",
        "    target_recovery = site.target_recovery_rate\n",
        "    status = site.status\n",
        "\n",
        "    for date in date_range:\n",
        "        # Skip production if site is in Care & Maintenance\n",
        "        if status == 'Care & Maintenance':\n",
        "            production_records.append({\n",
        "                'date': date.strftime('%Y-%m-%d'),\n",
        "                'site_id': site_id,\n",
        "                'site_name': site_name,\n",
        "                'commodity': commodity,\n",
        "                'status': 'Care & Maintenance',\n",
        "                'tonnes_mined': 0,\n",
        "                'tonnes_processed': 0,\n",
        "                'head_grade': 0.0,\n",
        "                'recovery_rate': 0.0,\n",
        "                'metal_produced': 0.0,\n",
        "                'plan_adherence_pct': 0.0,\n",
        "                'shift_1_tonnes': 0,\n",
        "                'shift_2_tonnes': 0,\n",
        "                'operational_hours': 0,\n",
        "                'downtime_hours': 24.0,\n",
        "                'weather_delay_hours': 0.0\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        # Seasonal factors (cyclones Jan-Mar for Pilbara)\n",
        "        is_cyclone_season = (date.month in [1, 2, 3]) and (site.region == 'Pilbara')\n",
        "        cyclone_impact = np.random.choice([0, 0, 0, 0.3, 0.5, 0.8], p=[0.85, 0.10, 0.03, 0.01, 0.005, 0.005]) if is_cyclone_season else 0\n",
        "\n",
        "        # Maintenance shutdowns (quarterly, 2-3 days)\n",
        "        is_maintenance = (date.day in [15, 16]) and (date.month in [3, 6, 9, 12])\n",
        "        maintenance_impact = 0.7 if is_maintenance else 0\n",
        "\n",
        "        # Base production efficiency (realistic variance)\n",
        "        base_efficiency = np.random.normal(0.95, 0.08)  # Mean 95%, std 8%\n",
        "        base_efficiency = np.clip(base_efficiency, 0.75, 1.10)  # Cap at 75%-110%\n",
        "\n",
        "        # Total impact\n",
        "        total_impact = max(cyclone_impact, maintenance_impact)\n",
        "        actual_efficiency = base_efficiency * (1 - total_impact)\n",
        "\n",
        "        # Calculate tonnes\n",
        "        tonnes_mined = int(daily_target * actual_efficiency * np.random.uniform(0.95, 1.05))\n",
        "        tonnes_processed = int(tonnes_mined * 0.98)  # 2% loss in handling\n",
        "\n",
        "        # Grade variability (Â±5% from target)\n",
        "        head_grade = target_grade * np.random.uniform(0.95, 1.05)\n",
        "\n",
        "        # Recovery rate (slightly below target on average)\n",
        "        recovery_rate = target_recovery * np.random.uniform(0.96, 1.02)\n",
        "        recovery_rate = np.clip(recovery_rate, target_recovery - 5, target_recovery + 2)\n",
        "\n",
        "        # Metal produced (varies by commodity)\n",
        "        if commodity == 'Gold':\n",
        "            # Gold: tonnes ore Ã— grade (g/t) Ã— recovery Ã— conversion to oz\n",
        "            metal_produced = (tonnes_processed * head_grade * recovery_rate / 100) / 31.1035  # oz\n",
        "        elif commodity == 'Iron Ore':\n",
        "            # Iron: just recovered tonnes (no conversion needed)\n",
        "            metal_produced = tonnes_processed * (recovery_rate / 100)\n",
        "        elif commodity == 'Lithium':\n",
        "            # Lithium: concentrate tonnes at SC6 grade\n",
        "            metal_produced = tonnes_processed * (head_grade / 100) * (recovery_rate / 100)\n",
        "        elif commodity == 'Copper':\n",
        "            # Copper: metal tonnes\n",
        "            metal_produced = tonnes_processed * (head_grade / 100) * (recovery_rate / 100)\n",
        "        else:\n",
        "            metal_produced = 0\n",
        "\n",
        "        # Plan adherence\n",
        "        plan_adherence = (tonnes_mined / daily_target * 100) if daily_target > 0 else 0\n",
        "        plan_adherence = np.clip(plan_adherence, 0, 110)\n",
        "\n",
        "        # Shift breakdown (12-hour shifts)\n",
        "        shift_split = np.random.uniform(0.45, 0.55)\n",
        "        shift_1_tonnes = int(tonnes_mined * shift_split)\n",
        "        shift_2_tonnes = tonnes_mined - shift_1_tonnes\n",
        "\n",
        "        # Hours\n",
        "        operational_hours = 24 * (1 - total_impact)\n",
        "        downtime_hours = 24 - operational_hours\n",
        "        weather_delay_hours = 24 * cyclone_impact if cyclone_impact > 0 else 0.0\n",
        "\n",
        "        production_records.append({\n",
        "            'date': date.strftime('%Y-%m-%d'),\n",
        "            'site_id': site_id,\n",
        "            'site_name': site_name,\n",
        "            'commodity': commodity,\n",
        "            'status': 'Operational',\n",
        "            'tonnes_mined': tonnes_mined,\n",
        "            'tonnes_processed': tonnes_processed,\n",
        "            'head_grade': round(head_grade, 2),\n",
        "            'recovery_rate': round(recovery_rate, 1),\n",
        "            'metal_produced': round(metal_produced, 2),\n",
        "            'plan_adherence_pct': round(plan_adherence, 1),\n",
        "            'shift_1_tonnes': shift_1_tonnes,\n",
        "            'shift_2_tonnes': shift_2_tonnes,\n",
        "            'operational_hours': round(operational_hours, 1),\n",
        "            'downtime_hours': round(downtime_hours, 1),\n",
        "            'weather_delay_hours': round(weather_delay_hours, 1)\n",
        "        })\n",
        "\n",
        "df_production = pd.DataFrame(production_records)\n",
        "\n",
        "print(f\"âœ“ Created daily production data: {len(df_production)} records\")\n",
        "print(f\"  Date range: {df_production['date'].min()} to {df_production['date'].max()}\")\n",
        "print(f\"  Total tonnes mined: {df_production['tonnes_mined'].sum():,.0f}\")\n",
        "\n",
        "# =====================================================\n",
        "# DATASET 3: EQUIPMENT PERFORMANCE DATA\n",
        "# =====================================================\n",
        "\n",
        "print(\"\\n[3/5] Generating Equipment Performance Data...\")\n",
        "\n",
        "# Equipment fleet definition\n",
        "equipment_fleet = [\n",
        "    # Iron Ridge (Autonomous, Pilbara)\n",
        "    {'site_id': 'IRON001', 'equipment_id': 'TRK-IR-001', 'equipment_type': 'Haul Truck', 'model': 'CAT 793F AHS', 'autonomous': True, 'target_util': 95},\n",
        "    {'site_id': 'IRON001', 'equipment_id': 'TRK-IR-002', 'equipment_type': 'Haul Truck', 'model': 'CAT 793F AHS', 'autonomous': True, 'target_util': 95},\n",
        "    {'site_id': 'IRON001', 'equipment_id': 'TRK-IR-003', 'equipment_type': 'Haul Truck', 'model': 'CAT 793F AHS', 'autonomous': True, 'target_util': 95},\n",
        "    {'site_id': 'IRON001', 'equipment_id': 'EXC-IR-001', 'equipment_type': 'Excavator', 'model': 'Liebherr R9800', 'autonomous': False, 'target_util': 82},\n",
        "    {'site_id': 'IRON001', 'equipment_id': 'EXC-IR-002', 'equipment_type': 'Excavator', 'model': 'Liebherr R9800', 'autonomous': False, 'target_util': 82},\n",
        "    {'site_id': 'IRON001', 'equipment_id': 'DOZ-IR-001', 'equipment_type': 'Dozer', 'model': 'CAT D11T', 'autonomous': False, 'target_util': 75},\n",
        "\n",
        "    # Golden Valley (Manual, Goldfields)\n",
        "    {'site_id': 'GOLD001', 'equipment_id': 'TRK-GV-001', 'equipment_type': 'Haul Truck', 'model': 'CAT 793F', 'autonomous': False, 'target_util': 80},\n",
        "    {'site_id': 'GOLD001', 'equipment_id': 'TRK-GV-002', 'equipment_type': 'Haul Truck', 'model': 'CAT 793F', 'autonomous': False, 'target_util': 80},\n",
        "    {'site_id': 'GOLD001', 'equipment_id': 'TRK-GV-003', 'equipment_type': 'Haul Truck', 'model': 'CAT 793F', 'autonomous': False, 'target_util': 80},\n",
        "    {'site_id': 'GOLD001', 'equipment_id': 'EXC-GV-001', 'equipment_type': 'Excavator', 'model': 'Liebherr R9800', 'autonomous': False, 'target_util': 82},\n",
        "    {'site_id': 'GOLD001', 'equipment_id': 'EXC-GV-002', 'equipment_type': 'Excavator', 'model': 'CAT 6060', 'autonomous': False, 'target_util': 82},\n",
        "    {'site_id': 'GOLD001', 'equipment_id': 'DOZ-GV-001', 'equipment_type': 'Dozer', 'model': 'CAT D11T', 'autonomous': False, 'target_util': 75},\n",
        "    {'site_id': 'GOLD001', 'equipment_id': 'DOZ-GV-002', 'equipment_type': 'Dozer', 'model': 'CAT D10T2', 'autonomous': False, 'target_util': 75},\n",
        "\n",
        "    # Lithium Creek (Semi-auto, Pilbara)\n",
        "    {'site_id': 'LITH001', 'equipment_id': 'TRK-LC-001', 'equipment_type': 'Haul Truck', 'model': 'CAT 793F', 'autonomous': False, 'target_util': 82},\n",
        "    {'site_id': 'LITH001', 'equipment_id': 'TRK-LC-002', 'equipment_type': 'Haul Truck', 'model': 'CAT 793F', 'autonomous': False, 'target_util': 82},\n",
        "    {'site_id': 'LITH001', 'equipment_id': 'EXC-LC-001', 'equipment_type': 'Excavator', 'model': 'CAT 6060', 'autonomous': False, 'target_util': 82},\n",
        "    {'site_id': 'LITH001', 'equipment_id': 'DOZ-LC-001', 'equipment_type': 'Dozer', 'model': 'CAT D10T2', 'autonomous': False, 'target_util': 75},\n",
        "\n",
        "    # Copper Hills (Underground equipment)\n",
        "    {'site_id': 'COPP001', 'equipment_id': 'LHD-CH-001', 'equipment_type': 'LHD Loader', 'model': 'CAT R1700', 'autonomous': False, 'target_util': 70},\n",
        "    {'site_id': 'COPP001', 'equipment_id': 'LHD-CH-002', 'equipment_type': 'LHD Loader', 'model': 'CAT R1700', 'autonomous': False, 'target_util': 70},\n",
        "    {'site_id': 'COPP001', 'equipment_id': 'LHD-CH-003', 'equipment_type': 'LHD Loader', 'model': 'Sandvik LH517i', 'autonomous': False, 'target_util': 70},\n",
        "    {'site_id': 'COPP001', 'equipment_id': 'DRL-CH-001', 'equipment_type': 'Jumbo Drill', 'model': 'Sandvik DD421', 'autonomous': False, 'target_util': 45},\n",
        "    {'site_id': 'COPP001', 'equipment_id': 'DRL-CH-002', 'equipment_type': 'Jumbo Drill', 'model': 'Sandvik DD422i', 'autonomous': False, 'target_util': 45},\n",
        "]\n",
        "\n",
        "equipment_records = []\n",
        "\n",
        "for equip in equipment_fleet:\n",
        "    site_id = equip['site_id']\n",
        "    equipment_id = equip['equipment_id']\n",
        "    equipment_type = equip['equipment_type']\n",
        "    model = equip['model']\n",
        "    is_autonomous = equip['autonomous']\n",
        "    target_util = equip['target_util']\n",
        "\n",
        "    # Get site status\n",
        "    site_status = df_sites[df_sites['site_id'] == site_id]['status'].values[0]\n",
        "\n",
        "    for date in date_range:\n",
        "        # If site is in care & maintenance, equipment is idle\n",
        "        if site_status == 'Care & Maintenance':\n",
        "            equipment_records.append({\n",
        "                'date': date.strftime('%Y-%m-%d'),\n",
        "                'site_id': site_id,\n",
        "                'equipment_id': equipment_id,\n",
        "                'equipment_type': equipment_type,\n",
        "                'model': model,\n",
        "                'autonomous': is_autonomous,\n",
        "                'available_hours': 0.0,\n",
        "                'operating_hours': 0.0,\n",
        "                'idle_hours': 24.0,\n",
        "                'maintenance_hours': 0.0,\n",
        "                'breakdown_hours': 0.0,\n",
        "                'availability_pct': 0.0,\n",
        "                'utilization_pct': 0.0,\n",
        "                'oee_pct': 0.0,\n",
        "                'fuel_consumed_liters': 0,\n",
        "                'maintenance_cost_aud': 0\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        # Random breakdown events (rare)\n",
        "        has_breakdown = np.random.random() < 0.02  # 2% chance per day\n",
        "        breakdown_hours = np.random.uniform(4, 12) if has_breakdown else 0\n",
        "\n",
        "        # Scheduled maintenance (every ~15 days)\n",
        "        has_maintenance = (date.day % 15 == 0)\n",
        "        maintenance_hours = np.random.uniform(2, 6) if has_maintenance else 0\n",
        "\n",
        "        # Total downtime\n",
        "        total_downtime = breakdown_hours + maintenance_hours\n",
        "        available_hours = 24 - total_downtime\n",
        "\n",
        "        # Operating hours (% of available time)\n",
        "        util_variance = np.random.normal(1.0, 0.1)\n",
        "        actual_util = (target_util / 100) * util_variance\n",
        "        actual_util = np.clip(actual_util, 0.5, 1.0)\n",
        "        operating_hours = available_hours * actual_util\n",
        "        idle_hours = available_hours - operating_hours\n",
        "\n",
        "        # Calculate metrics\n",
        "        availability_pct = (available_hours / 24) * 100\n",
        "        utilization_pct = (operating_hours / available_hours * 100) if available_hours > 0 else 0\n",
        "        oee_pct = (operating_hours / 24) * 100  # Simplified OEE\n",
        "\n",
        "        # Fuel consumption (varies by equipment type)\n",
        "        if equipment_type == 'Haul Truck':\n",
        "            fuel_per_hour = 180  # liters/hour\n",
        "        elif equipment_type == 'Excavator':\n",
        "            fuel_per_hour = 400\n",
        "        elif equipment_type == 'Dozer':\n",
        "            fuel_per_hour = 120\n",
        "        elif equipment_type == 'LHD Loader':\n",
        "            fuel_per_hour = 80\n",
        "        elif equipment_type == 'Jumbo Drill':\n",
        "            fuel_per_hour = 60\n",
        "        else:\n",
        "            fuel_per_hour = 100\n",
        "\n",
        "        fuel_consumed = int(operating_hours * fuel_per_hour)\n",
        "\n",
        "        # Maintenance costs\n",
        "        if has_maintenance:\n",
        "            maintenance_cost = np.random.uniform(5000, 15000)\n",
        "        elif has_breakdown:\n",
        "            maintenance_cost = np.random.uniform(20000, 80000)\n",
        "        else:\n",
        "            maintenance_cost = np.random.uniform(500, 2000)  # Daily wear\n",
        "\n",
        "        equipment_records.append({\n",
        "            'date': date.strftime('%Y-%m-%d'),\n",
        "            'site_id': site_id,\n",
        "            'equipment_id': equipment_id,\n",
        "            'equipment_type': equipment_type,\n",
        "            'model': model,\n",
        "            'autonomous': is_autonomous,\n",
        "            'available_hours': round(available_hours, 1),\n",
        "            'operating_hours': round(operating_hours, 1),\n",
        "            'idle_hours': round(idle_hours, 1),\n",
        "            'maintenance_hours': round(maintenance_hours, 1),\n",
        "            'breakdown_hours': round(breakdown_hours, 1),\n",
        "            'availability_pct': round(availability_pct, 1),\n",
        "            'utilization_pct': round(utilization_pct, 1),\n",
        "            'oee_pct': round(oee_pct, 1),\n",
        "            'fuel_consumed_liters': fuel_consumed,\n",
        "            'maintenance_cost_aud': round(maintenance_cost, 2)\n",
        "        })\n",
        "\n",
        "df_equipment = pd.DataFrame(equipment_records)\n",
        "\n",
        "print(f\"âœ“ Created equipment performance data: {len(df_equipment)} records\")\n",
        "print(f\"  Equipment units tracked: {len(equipment_fleet)}\")\n",
        "print(f\"  Total operating hours: {df_equipment['operating_hours'].sum():,.0f}\")\n",
        "\n",
        "# =====================================================\n",
        "# DATASET 4: SAFETY INCIDENTS DATA\n",
        "# =====================================================\n",
        "\n",
        "print(\"\\n[4/5] Generating Safety Incidents Data...\")\n",
        "\n",
        "# Safety incident types and their frequency (per year per site)\n",
        "incident_types = [\n",
        "    {'type': 'Lost Time Injury (LTI)', 'frequency': 2, 'severity': 'High'},\n",
        "    {'type': 'Medical Treatment Injury (MTI)', 'frequency': 8, 'severity': 'Medium'},\n",
        "    {'type': 'First Aid Injury (FAI)', 'frequency': 20, 'severity': 'Low'},\n",
        "    {'type': 'Potential Significant Incident (PSI)', 'frequency': 15, 'severity': 'Medium'},\n",
        "    {'type': 'Near Miss', 'frequency': 40, 'severity': 'Low'},\n",
        "    {'type': 'Environmental Incident', 'frequency': 5, 'severity': 'Medium'},\n",
        "]\n",
        "\n",
        "safety_records = []\n",
        "incident_id_counter = 1\n",
        "\n",
        "for site in df_sites.itertuples():\n",
        "    if site.status == 'Care & Maintenance':\n",
        "        continue  # Minimal incidents for closed sites\n",
        "\n",
        "    site_id = site.site_id\n",
        "    site_name = site.site_name\n",
        "    workforce = site.workforce_count\n",
        "\n",
        "    # Generate incidents throughout the year\n",
        "    for incident_type in incident_types:\n",
        "        num_incidents = incident_type['frequency']\n",
        "\n",
        "        # Randomly distribute incidents across the year\n",
        "        incident_dates = sorted(random.sample(list(date_range), min(num_incidents, 365)))\n",
        "\n",
        "        for inc_date in incident_dates:\n",
        "            # Incident details\n",
        "            incident_description = {\n",
        "                'Lost Time Injury (LTI)': ['Fall from height', 'Crush injury', 'Struck by equipment', 'Back strain'],\n",
        "                'Medical Treatment Injury (MTI)': ['Laceration', 'Minor burn', 'Sprain', 'Contusion'],\n",
        "                'First Aid Injury (FAI)': ['Minor cut', 'Scrape', 'Splinter', 'Minor bruise'],\n",
        "                'Potential Significant Incident (PSI)': ['Near miss vehicle collision', 'Geotechnical movement', 'Equipment malfunction', 'Uncontrolled energy release'],\n",
        "                'Near Miss': ['Pedestrian near vehicle', 'Falling object', 'Slip/trip hazard', 'Equipment proximity'],\n",
        "                'Environmental Incident': ['Minor fuel spill', 'Dust exceedance', 'Water quality issue', 'Waste handling'],\n",
        "            }\n",
        "\n",
        "            description = random.choice(incident_description[incident_type['type']])\n",
        "\n",
        "            # Days lost (only for LTI)\n",
        "            days_lost = random.randint(5, 30) if incident_type['type'] == 'Lost Time Injury (LTI)' else 0\n",
        "\n",
        "            # Root cause\n",
        "            root_causes = ['Human Error', 'Equipment Failure', 'Procedural Gap', 'Environmental Factor', 'Training Gap']\n",
        "            root_cause = random.choice(root_causes)\n",
        "\n",
        "            # Investigation status\n",
        "            status_options = ['Closed', 'Closed', 'Closed', 'Under Investigation']  # Most closed\n",
        "            investigation_status = random.choice(status_options)\n",
        "\n",
        "            safety_records.append({\n",
        "                'incident_id': f'INC-{incident_id_counter:05d}',\n",
        "                'date': inc_date.strftime('%Y-%m-%d'),\n",
        "                'site_id': site_id,\n",
        "                'site_name': site_name,\n",
        "                'incident_type': incident_type['type'],\n",
        "                'severity': incident_type['severity'],\n",
        "                'description': description,\n",
        "                'days_lost': days_lost,\n",
        "                'root_cause': root_cause,\n",
        "                'investigation_status': investigation_status,\n",
        "                'workforce_size': workforce\n",
        "            })\n",
        "\n",
        "            incident_id_counter += 1\n",
        "\n",
        "df_safety = pd.DataFrame(safety_records)\n",
        "\n",
        "# Calculate TRIFR and LTIFR (per million hours worked)\n",
        "# Assume 12-hour shifts, 365 days, workforce size\n",
        "def calculate_safety_metrics(df_sites, df_safety):\n",
        "    metrics = []\n",
        "    for site in df_sites.itertuples():\n",
        "        if site.status == 'Care & Maintenance':\n",
        "            continue\n",
        "\n",
        "        site_id = site.site_id\n",
        "        workforce = site.workforce_count\n",
        "\n",
        "        # Total hours worked (workforce Ã— 12 hours Ã— 365 days)\n",
        "        total_hours = workforce * 12 * 365\n",
        "\n",
        "        # Count incidents\n",
        "        site_incidents = df_safety[df_safety['site_id'] == site_id]\n",
        "        lti_count = len(site_incidents[site_incidents['incident_type'] == 'Lost Time Injury (LTI)'])\n",
        "        mti_count = len(site_incidents[site_incidents['incident_type'] == 'Medical Treatment Injury (MTI)'])\n",
        "        total_recordable = lti_count + mti_count\n",
        "\n",
        "        # Calculate rates (per million hours)\n",
        "        trifr = (total_recordable / total_hours) * 1_000_000\n",
        "        ltifr = (lti_count / total_hours) * 1_000_000\n",
        "\n",
        "        metrics.append({\n",
        "            'site_id': site_id,\n",
        "            'site_name': site.site_name,\n",
        "            'total_hours_worked': total_hours,\n",
        "            'lti_count': lti_count,\n",
        "            'mti_count': mti_count,\n",
        "            'trifr': round(trifr, 2),\n",
        "            'ltifr': round(ltifr, 2)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(metrics)\n",
        "\n",
        "df_safety_metrics = calculate_safety_metrics(df_sites, df_safety)\n",
        "\n",
        "print(f\"âœ“ Created safety incidents data: {len(df_safety)} incidents\")\n",
        "print(\"\\nSafety Performance by Site:\")\n",
        "print(df_safety_metrics.to_string(index=False))\n",
        "\n",
        "# =====================================================\n",
        "# DATASET 5: DAILY OPERATING COSTS\n",
        "# =====================================================\n",
        "\n",
        "print(\"\\n[5/5] Generating Daily Operating Costs Data...\")\n",
        "\n",
        "cost_records = []\n",
        "\n",
        "for site in df_sites.itertuples():\n",
        "    site_id = site.site_id\n",
        "    site_name = site.site_name\n",
        "    commodity = site.commodity\n",
        "    status = site.status\n",
        "    cost_target = site.cost_per_unit_target\n",
        "    workforce = site.workforce_count\n",
        "\n",
        "    for date in date_range:\n",
        "        # Get production for this date\n",
        "        prod_data = df_production[(df_production['site_id'] == site_id) & (df_production['date'] == date.strftime('%Y-%m-%d'))]\n",
        "\n",
        "        if len(prod_data) == 0:\n",
        "            continue\n",
        "\n",
        "        tonnes_mined = prod_data['tonnes_mined'].values[0]\n",
        "        metal_produced = prod_data['metal_produced'].values[0]\n",
        "\n",
        "        # If care & maintenance\n",
        "        if status == 'Care & Maintenance':\n",
        "            cost_records.append({\n",
        "                'date': date.strftime('%Y-%m-%d'),\n",
        "                'site_id': site_id,\n",
        "                'site_name': site_name,\n",
        "                'commodity': commodity,\n",
        "                'labor_cost_aud': 5000,  # Skeleton crew\n",
        "                'equipment_cost_aud': 0,\n",
        "                'fuel_cost_aud': 0,\n",
        "                'maintenance_cost_aud': 2000,\n",
        "                'consumables_cost_aud': 0,\n",
        "                'utilities_cost_aud': 1000,\n",
        "                'admin_cost_aud': 500,\n",
        "                'total_cost_aud': 8500,\n",
        "                'tonnes_produced': 0,\n",
        "                'cost_per_unit': 0\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        # Cost breakdown (realistic percentages from research)\n",
        "        # Base daily costs\n",
        "        if commodity == 'Iron Ore':\n",
        "            base_daily_cost = 137000 * 27  # Daily target Ã— cost per tonne\n",
        "        elif commodity == 'Gold':\n",
        "            base_daily_cost = (35600 / 31.1) * 2500  # Tonnes to oz Ã— cost per oz\n",
        "        elif commodity == 'Lithium':\n",
        "            base_daily_cost = 1920 * 640\n",
        "        elif commodity == 'Copper':\n",
        "            base_daily_cost = 55 * 2.2 * 1.85 * 1000  # Tonnes to lb Ã— cost per lb\n",
        "        else:\n",
        "            base_daily_cost = 100000\n",
        "\n",
        "        # Adjust for actual production\n",
        "        production_ratio = tonnes_mined / site.daily_target_tonnes if site.daily_target_tonnes > 0 else 0\n",
        "        daily_cost = base_daily_cost * production_ratio * np.random.uniform(0.95, 1.05)\n",
        "\n",
        "        # Breakdown\n",
        "        labor_cost = daily_cost * 0.40\n",
        "        equipment_cost = daily_cost * 0.28\n",
        "        fuel_cost = daily_cost * 0.18\n",
        "        maintenance_cost = daily_cost * 0.08\n",
        "        consumables_cost = daily_cost * 0.04\n",
        "        utilities_cost = daily_cost * 0.01\n",
        "        admin_cost = daily_cost * 0.01\n",
        "\n",
        "        total_cost = labor_cost + equipment_cost + fuel_cost + maintenance_cost + consumables_cost + utilities_cost + admin_cost\n",
        "\n",
        "        # Cost per unit\n",
        "        if commodity == 'Gold':\n",
        "            cost_per_unit = (total_cost / metal_produced) if metal_produced > 0 else 0  # AUD per oz\n",
        "        elif commodity == 'Iron Ore':\n",
        "            cost_per_unit = (total_cost / tonnes_mined) if tonnes_mined > 0 else 0  # AUD per tonne\n",
        "        elif commodity == 'Lithium':\n",
        "            cost_per_unit = (total_cost / metal_produced) if metal_produced > 0 else 0  # AUD per tonne concentrate\n",
        "        elif commodity == 'Copper':\n",
        "            cost_per_unit = (total_cost / (metal_produced * 1000 * 2.2)) if metal_produced > 0 else 0  # AUD per lb\n",
        "        else:\n",
        "            cost_per_unit = 0\n",
        "\n",
        "        cost_records.append({\n",
        "            'date': date.strftime('%Y-%m-%d'),\n",
        "            'site_id': site_id,\n",
        "            'site_name': site_name,\n",
        "            'commodity': commodity,\n",
        "            'labor_cost_aud': round(labor_cost, 2),\n",
        "            'equipment_cost_aud': round(equipment_cost, 2),\n",
        "            'fuel_cost_aud': round(fuel_cost, 2),\n",
        "            'maintenance_cost_aud': round(maintenance_cost, 2),\n",
        "            'consumables_cost_aud': round(consumables_cost, 2),\n",
        "            'utilities_cost_aud': round(utilities_cost, 2),\n",
        "            'admin_cost_aud': round(admin_cost, 2),\n",
        "            'total_cost_aud': round(total_cost, 2),\n",
        "            'tonnes_produced': tonnes_mined,\n",
        "            'cost_per_unit': round(cost_per_unit, 2)\n",
        "        })\n",
        "\n",
        "df_costs = pd.DataFrame(cost_records)\n",
        "\n",
        "print(f\"âœ“ Created daily operating costs data: {len(df_costs)} records\")\n",
        "print(f\"  Total operating costs: ${df_costs['total_cost_aud'].sum():,.0f} AUD\")\n",
        "\n",
        "# =====================================================\n",
        "# DATA QUALITY SUMMARY\n",
        "# =====================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DATA GENERATION COMPLETE!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nðŸ“Š DATASET SUMMARY:\")\n",
        "print(f\"  1. Mine Sites: {len(df_sites)} sites\")\n",
        "print(f\"  2. Daily Production: {len(df_production)} records ({len(date_range)} days Ã— {len(df_sites)} sites)\")\n",
        "print(f\"  3. Equipment Performance: {len(df_equipment)} records ({len(date_range)} days Ã— {len(equipment_fleet)} units)\")\n",
        "print(f\"  4. Safety Incidents: {len(df_safety)} incidents\")\n",
        "print(f\"  5. Daily Costs: {len(df_costs)} records\")\n",
        "\n",
        "print(\"\\nðŸ’¾ SAVING CSV FILES...\")\n",
        "\n",
        "# Save all datasets\n",
        "df_sites.to_csv('mine_sites.csv', index=False)\n",
        "print(\"  âœ“ mine_sites.csv\")\n",
        "\n",
        "df_production.to_csv('daily_production.csv', index=False)\n",
        "print(\"  âœ“ daily_production.csv\")\n",
        "\n",
        "df_equipment.to_csv('equipment_performance.csv', index=False)\n",
        "print(\"  âœ“ equipment_performance.csv\")\n",
        "\n",
        "df_safety.to_csv('safety_incidents.csv', index=False)\n",
        "print(\"  âœ“ safety_incidents.csv\")\n",
        "\n",
        "df_costs.to_csv('daily_costs.csv', index=False)\n",
        "print(\"  âœ“ daily_costs.csv\")\n",
        "\n",
        "df_safety_metrics.to_csv('safety_metrics_summary.csv', index=False)\n",
        "print(\"  âœ“ safety_metrics_summary.csv (bonus file)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"âœ… ALL FILES READY FOR DOWNLOAD!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nðŸ“¥ NEXT STEPS:\")\n",
        "print(\"  1. Download all CSV files using the folder icon (left sidebar)\")\n",
        "print(\"  2. Create a 'data/' folder in your project\")\n",
        "print(\"  3. Move all CSVs into the data folder\")\n",
        "print(\"  4. Ready for SQLite database creation!\")\n",
        "\n",
        "print(\"\\nðŸ“ˆ QUICK DATA PREVIEW:\")\n",
        "print(\"\\n--- Mine Sites ---\")\n",
        "print(df_sites[['site_id', 'site_name', 'commodity', 'status', 'daily_target_tonnes']].head())\n",
        "\n",
        "print(\"\\n--- Production Sample (First 5 Days, Iron Ridge) ---\")\n",
        "print(df_production[df_production['site_id'] == 'IRON001'].head()[['date', 'site_name', 'tonnes_mined', 'plan_adherence_pct']])\n",
        "\n",
        "print(\"\\n--- Equipment Sample (Iron Ridge Truck) ---\")\n",
        "print(df_equipment[df_equipment['equipment_id'] == 'TRK-IR-001'].head()[['date', 'equipment_id', 'availability_pct', 'utilization_pct', 'oee_pct']])\n",
        "\n",
        "print(\"\\n--- Safety Incidents by Type ---\")\n",
        "print(df_safety['incident_type'].value_counts())\n",
        "\n",
        "print(\"\\n--- Cost Summary by Site ---\")\n",
        "cost_summary = df_costs.groupby(['site_name', 'commodity']).agg({\n",
        "    'total_cost_aud': 'sum',\n",
        "    'cost_per_unit': 'mean'\n",
        "}).reset_index()\n",
        "cost_summary['total_cost_aud'] = cost_summary['total_cost_aud'].apply(lambda x: f\"${x:,.0f}\")\n",
        "cost_summary['cost_per_unit'] = cost_summary['cost_per_unit'].apply(lambda x: f\"${x:.2f}\")\n",
        "print(cost_summary.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ðŸŽ‰ DATA GENERATION SCRIPT COMPLETE!\")\n",
        "print(\"Based on real 2025 WA mining industry data\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JVCeJbUdvE1v",
        "outputId": "a621d5dd-6a06-4c92-e60a-0ee8d42361de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "WA MINING OPERATIONS DATA GENERATOR\n",
            "Generating realistic 2025 mining data for 5 WA mine sites\n",
            "============================================================\n",
            "\n",
            "[1/5] Generating Mine Sites Master Data...\n",
            "âœ“ Created mine sites data: 5 sites\n",
            "site_id          site_name commodity             status\n",
            "IRON001    Iron Ridge Mine  Iron Ore        Operational\n",
            "GOLD001 Golden Valley Mine      Gold        Operational\n",
            "LITH001 Lithium Creek Mine   Lithium        Operational\n",
            "COPP001  Copper Hills Mine    Copper        Operational\n",
            "NICK001  Nickel Point Mine    Nickel Care & Maintenance\n",
            "\n",
            "[2/5] Generating Daily Production Data (365 days)...\n",
            "âœ“ Created daily production data: 1825 records\n",
            "  Date range: 2025-01-01 to 2025-12-31\n",
            "  Total tonnes mined: 59,706,811\n",
            "\n",
            "[3/5] Generating Equipment Performance Data...\n",
            "âœ“ Created equipment performance data: 8030 records\n",
            "  Equipment units tracked: 22\n",
            "  Total operating hours: 146,822\n",
            "\n",
            "[4/5] Generating Safety Incidents Data...\n",
            "âœ“ Created safety incidents data: 360 incidents\n",
            "\n",
            "Safety Performance by Site:\n",
            "site_id          site_name  total_hours_worked  lti_count  mti_count  trifr  ltifr\n",
            "IRON001    Iron Ridge Mine             3723000          2          8   2.69   0.54\n",
            "GOLD001 Golden Valley Mine             5256000          2          8   1.90   0.38\n",
            "LITH001 Lithium Creek Mine             1971000          2          8   5.07   1.01\n",
            "COPP001  Copper Hills Mine             1226400          2          8   8.15   1.63\n",
            "\n",
            "[5/5] Generating Daily Operating Costs Data...\n",
            "âœ“ Created daily operating costs data: 1825 records\n",
            "  Total operating costs: $2,736,540,927 AUD\n",
            "\n",
            "============================================================\n",
            "DATA GENERATION COMPLETE!\n",
            "============================================================\n",
            "\n",
            "ðŸ“Š DATASET SUMMARY:\n",
            "  1. Mine Sites: 5 sites\n",
            "  2. Daily Production: 1825 records (365 days Ã— 5 sites)\n",
            "  3. Equipment Performance: 8030 records (365 days Ã— 22 units)\n",
            "  4. Safety Incidents: 360 incidents\n",
            "  5. Daily Costs: 1825 records\n",
            "\n",
            "ðŸ’¾ SAVING CSV FILES...\n",
            "  âœ“ mine_sites.csv\n",
            "  âœ“ daily_production.csv\n",
            "  âœ“ equipment_performance.csv\n",
            "  âœ“ safety_incidents.csv\n",
            "  âœ“ daily_costs.csv\n",
            "  âœ“ safety_metrics_summary.csv (bonus file)\n",
            "\n",
            "============================================================\n",
            "âœ… ALL FILES READY FOR DOWNLOAD!\n",
            "============================================================\n",
            "\n",
            "ðŸ“¥ NEXT STEPS:\n",
            "  1. Download all CSV files using the folder icon (left sidebar)\n",
            "  2. Create a 'data/' folder in your project\n",
            "  3. Move all CSVs into the data folder\n",
            "  4. Ready for SQLite database creation!\n",
            "\n",
            "ðŸ“ˆ QUICK DATA PREVIEW:\n",
            "\n",
            "--- Mine Sites ---\n",
            "   site_id           site_name commodity              status  \\\n",
            "0  IRON001     Iron Ridge Mine  Iron Ore         Operational   \n",
            "1  GOLD001  Golden Valley Mine      Gold         Operational   \n",
            "2  LITH001  Lithium Creek Mine   Lithium         Operational   \n",
            "3  COPP001   Copper Hills Mine    Copper         Operational   \n",
            "4  NICK001   Nickel Point Mine    Nickel  Care & Maintenance   \n",
            "\n",
            "   daily_target_tonnes  \n",
            "0               137000  \n",
            "1                35600  \n",
            "2                 1920  \n",
            "3                   55  \n",
            "4                    0  \n",
            "\n",
            "--- Production Sample (First 5 Days, Iron Ridge) ---\n",
            "         date        site_name  tonnes_mined  plan_adherence_pct\n",
            "0  2025-01-01  Iron Ridge Mine        113905                83.1\n",
            "1  2025-01-02  Iron Ridge Mine        127238                92.9\n",
            "2  2025-01-03  Iron Ridge Mine        124194                90.7\n",
            "3  2025-01-04  Iron Ridge Mine        117527                85.8\n",
            "4  2025-01-05  Iron Ridge Mine        143865               105.0\n",
            "\n",
            "--- Equipment Sample (Iron Ridge Truck) ---\n",
            "         date equipment_id  availability_pct  utilization_pct  oee_pct\n",
            "0  2025-01-01   TRK-IR-001             100.0            100.0    100.0\n",
            "1  2025-01-02   TRK-IR-001             100.0             86.1     86.1\n",
            "2  2025-01-03   TRK-IR-001             100.0             88.1     88.1\n",
            "3  2025-01-04   TRK-IR-001             100.0             94.0     94.0\n",
            "4  2025-01-05   TRK-IR-001             100.0             85.1     85.1\n",
            "\n",
            "--- Safety Incidents by Type ---\n",
            "incident_type\n",
            "Near Miss                               160\n",
            "First Aid Injury (FAI)                   80\n",
            "Potential Significant Incident (PSI)     60\n",
            "Medical Treatment Injury (MTI)           32\n",
            "Environmental Incident                   20\n",
            "Lost Time Injury (LTI)                    8\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Cost Summary by Site ---\n",
            "         site_name commodity total_cost_aud cost_per_unit\n",
            " Copper Hills Mine    Copper    $75,432,397        $78.76\n",
            "Golden Valley Mine      Gold   $970,956,818      $2355.21\n",
            "   Iron Ridge Mine  Iron Ore $1,269,625,942        $27.05\n",
            "Lithium Creek Mine   Lithium   $417,423,270     $72323.40\n",
            " Nickel Point Mine    Nickel     $3,102,500         $0.00\n",
            "\n",
            "============================================================\n",
            "ðŸŽ‰ DATA GENERATION SCRIPT COMPLETE!\n",
            "Based on real 2025 WA mining industry data\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Create a zip file with all CSVs\n",
        "!zip mining_data.zip *.csv\n",
        "\n",
        "# Download the zip\n",
        "files.download('mining_data.zip')\n",
        "\n",
        "print(\"âœ“ All files zipped and ready for download!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "collapsed": true,
        "id": "LKi6mh6Qvar8",
        "outputId": "8f3fb426-2f3b-42ab-9f66-ada9e19b3d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: daily_costs.csv (deflated 73%)\n",
            "  adding: daily_production.csv (deflated 83%)\n",
            "  adding: equipment_performance.csv (deflated 87%)\n",
            "  adding: mine_sites.csv (deflated 41%)\n",
            "  adding: safety_incidents.csv (deflated 91%)\n",
            "  adding: safety_metrics_summary.csv (deflated 27%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9c47f844-1283-4951-8c9f-721947a639e5\", \"mining_data.zip\", 218721)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ All files zipped and ready for download!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# MINING OPERATIONS DATABASE CREATOR\n",
        "# Creates SQLite database from CSV files\n",
        "# =====================================================\n",
        "\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"MINING OPERATIONS DATABASE CREATOR\")\n",
        "print(\"Creating SQLite database from CSV files...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# =====================================================\n",
        "# STEP 1: LOAD ALL CSV FILES\n",
        "# =====================================================\n",
        "\n",
        "print(\"\\n[1/3] Loading CSV files...\")\n",
        "\n",
        "try:\n",
        "    df_sites = pd.read_csv('mine_sites.csv')\n",
        "    print(f\"  âœ“ Loaded mine_sites.csv ({len(df_sites)} records)\")\n",
        "\n",
        "    df_production = pd.read_csv('daily_production.csv')\n",
        "    print(f\"  âœ“ Loaded daily_production.csv ({len(df_production)} records)\")\n",
        "\n",
        "    df_equipment = pd.read_csv('equipment_performance.csv')\n",
        "    print(f\"  âœ“ Loaded equipment_performance.csv ({len(df_equipment)} records)\")\n",
        "\n",
        "    df_safety = pd.read_csv('safety_incidents.csv')\n",
        "    print(f\"  âœ“ Loaded safety_incidents.csv ({len(df_safety)} records)\")\n",
        "\n",
        "    df_costs = pd.read_csv('daily_costs.csv')\n",
        "    print(f\"  âœ“ Loaded daily_costs.csv ({len(df_costs)} records)\")\n",
        "\n",
        "    df_safety_metrics = pd.read_csv('safety_metrics_summary.csv')\n",
        "    print(f\"  âœ“ Loaded safety_metrics_summary.csv ({len(df_safety_metrics)} records)\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\nâŒ ERROR: Could not find CSV files!\")\n",
        "    print(f\"   Make sure all CSV files are in the same folder as this script.\")\n",
        "    print(f\"   Missing file: {e.filename}\")\n",
        "    exit()\n",
        "\n",
        "# =====================================================\n",
        "# STEP 2: CREATE SQLite DATABASE\n",
        "# =====================================================\n",
        "\n",
        "print(\"\\n[2/3] Creating SQLite database...\")\n",
        "\n",
        "# Create database connection\n",
        "db_name = 'mining_operations.db'\n",
        "conn = sqlite3.connect(db_name)\n",
        "\n",
        "print(f\"  âœ“ Created database: {db_name}\")\n",
        "\n",
        "# =====================================================\n",
        "# STEP 3: CREATE TABLES AND LOAD DATA\n",
        "# =====================================================\n",
        "\n",
        "print(\"\\n[3/3] Creating tables and loading data...\")\n",
        "\n",
        "# Table 1: Mine Sites (Master Data)\n",
        "df_sites.to_sql('mine_sites', conn, if_exists='replace', index=False)\n",
        "print(f\"  âœ“ Created table: mine_sites ({len(df_sites)} records)\")\n",
        "\n",
        "# Table 2: Daily Production\n",
        "df_production.to_sql('daily_production', conn, if_exists='replace', index=False)\n",
        "print(f\"  âœ“ Created table: daily_production ({len(df_production)} records)\")\n",
        "\n",
        "# Table 3: Equipment Performance\n",
        "df_equipment.to_sql('equipment_performance', conn, if_exists='replace', index=False)\n",
        "print(f\"  âœ“ Created table: equipment_performance ({len(df_equipment)} records)\")\n",
        "\n",
        "# Table 4: Safety Incidents\n",
        "df_safety.to_sql('safety_incidents', conn, if_exists='replace', index=False)\n",
        "print(f\"  âœ“ Created table: safety_incidents ({len(df_safety)} records)\")\n",
        "\n",
        "# Table 5: Daily Costs\n",
        "df_costs.to_sql('daily_costs', conn, if_exists='replace', index=False)\n",
        "print(f\"  âœ“ Created table: daily_costs ({len(df_costs)} records)\")\n",
        "\n",
        "# Table 6: Safety Metrics Summary\n",
        "df_safety_metrics.to_sql('safety_metrics_summary', conn, if_exists='replace', index=False)\n",
        "print(f\"  âœ“ Created table: safety_metrics_summary ({len(df_safety_metrics)} records)\")\n",
        "\n",
        "# =====================================================\n",
        "# CREATE INDEXES FOR PERFORMANCE\n",
        "# =====================================================\n",
        "\n",
        "print(\"\\n[BONUS] Creating indexes for query performance...\")\n",
        "\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Indexes on frequently queried columns\n",
        "indexes = [\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_production_site_date ON daily_production(site_id, date);\",\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_production_date ON daily_production(date);\",\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_equipment_site_date ON equipment_performance(site_id, date);\",\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_equipment_id ON equipment_performance(equipment_id);\",\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_safety_site_date ON safety_incidents(site_id, date);\",\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_costs_site_date ON daily_costs(site_id, date);\",\n",
        "]\n",
        "\n",
        "for idx_sql in indexes:\n",
        "    cursor.execute(idx_sql)\n",
        "    print(f\"  âœ“ Created index\")\n",
        "\n",
        "conn.commit()\n",
        "\n",
        "# =====================================================\n",
        "# VERIFY DATABASE STRUCTURE\n",
        "# =====================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DATABASE STRUCTURE:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Get table list\n",
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "tables = cursor.fetchall()\n",
        "\n",
        "for table in tables:\n",
        "    table_name = table[0]\n",
        "    cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
        "    count = cursor.fetchone()[0]\n",
        "    print(f\"  ðŸ“Š {table_name}: {count:,} records\")\n",
        "\n",
        "# =====================================================\n",
        "# TEST QUERIES\n",
        "# =====================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"RUNNING TEST QUERIES:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test Query 1: Total production by site\n",
        "print(\"\\n--- Total Production by Site (2025) ---\")\n",
        "query1 = \"\"\"\n",
        "SELECT\n",
        "    site_name,\n",
        "    commodity,\n",
        "    SUM(tonnes_mined) as total_tonnes,\n",
        "    ROUND(AVG(plan_adherence_pct), 1) as avg_plan_adherence\n",
        "FROM daily_production\n",
        "WHERE status = 'Operational'\n",
        "GROUP BY site_name, commodity\n",
        "ORDER BY total_tonnes DESC;\n",
        "\"\"\"\n",
        "result1 = pd.read_sql_query(query1, conn)\n",
        "print(result1.to_string(index=False))\n",
        "\n",
        "# Test Query 2: Equipment availability by type\n",
        "print(\"\\n--- Equipment Availability by Type ---\")\n",
        "query2 = \"\"\"\n",
        "SELECT\n",
        "    equipment_type,\n",
        "    COUNT(DISTINCT equipment_id) as unit_count,\n",
        "    ROUND(AVG(availability_pct), 1) as avg_availability,\n",
        "    ROUND(AVG(utilization_pct), 1) as avg_utilization,\n",
        "    ROUND(AVG(oee_pct), 1) as avg_oee\n",
        "FROM equipment_performance\n",
        "GROUP BY equipment_type\n",
        "ORDER BY avg_oee DESC;\n",
        "\"\"\"\n",
        "result2 = pd.read_sql_query(query2, conn)\n",
        "print(result2.to_string(index=False))\n",
        "\n",
        "# Test Query 3: Safety performance\n",
        "print(\"\\n--- Safety Performance by Site ---\")\n",
        "query3 = \"\"\"\n",
        "SELECT\n",
        "    site_name,\n",
        "    trifr,\n",
        "    ltifr,\n",
        "    lti_count,\n",
        "    mti_count\n",
        "FROM safety_metrics_summary\n",
        "ORDER BY trifr;\n",
        "\"\"\"\n",
        "result3 = pd.read_sql_query(query3, conn)\n",
        "print(result3.to_string(index=False))\n",
        "\n",
        "# Test Query 4: Cost efficiency by site\n",
        "print(\"\\n--- Cost Efficiency by Site ---\")\n",
        "query4 = \"\"\"\n",
        "SELECT\n",
        "    site_name,\n",
        "    commodity,\n",
        "    ROUND(AVG(cost_per_unit), 2) as avg_cost_per_unit,\n",
        "    ROUND(SUM(total_cost_aud) / 1000000, 2) as total_cost_millions_aud\n",
        "FROM daily_costs\n",
        "WHERE commodity != 'Nickel'  -- Exclude Care & Maintenance site\n",
        "GROUP BY site_name, commodity\n",
        "ORDER BY total_cost_millions_aud DESC;\n",
        "\"\"\"\n",
        "result4 = pd.read_sql_query(query4, conn)\n",
        "print(result4.to_string(index=False))\n",
        "\n",
        "# Close connection\n",
        "conn.close()\n",
        "\n",
        "# =====================================================\n",
        "# DOWNLOAD DATABASE FILE\n",
        "# =====================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"âœ… DATABASE CREATION COMPLETE!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nðŸ“¦ Database file created: {db_name}\")\n",
        "print(f\"   Size: {pd.io.common.get_handle(db_name, 'rb').handle.seek(0, 2) / 1024 / 1024:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mYbEo2SxwKa8",
        "outputId": "f0d1d9c9-d39a-4283-b21c-2407237708cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "MINING OPERATIONS DATABASE CREATOR\n",
            "Creating SQLite database from CSV files...\n",
            "============================================================\n",
            "\n",
            "[1/3] Loading CSV files...\n",
            "  âœ“ Loaded mine_sites.csv (5 records)\n",
            "  âœ“ Loaded daily_production.csv (1825 records)\n",
            "  âœ“ Loaded equipment_performance.csv (8030 records)\n",
            "  âœ“ Loaded safety_incidents.csv (360 records)\n",
            "  âœ“ Loaded daily_costs.csv (1825 records)\n",
            "  âœ“ Loaded safety_metrics_summary.csv (4 records)\n",
            "\n",
            "[2/3] Creating SQLite database...\n",
            "  âœ“ Created database: mining_operations.db\n",
            "\n",
            "[3/3] Creating tables and loading data...\n",
            "  âœ“ Created table: mine_sites (5 records)\n",
            "  âœ“ Created table: daily_production (1825 records)\n",
            "  âœ“ Created table: equipment_performance (8030 records)\n",
            "  âœ“ Created table: safety_incidents (360 records)\n",
            "  âœ“ Created table: daily_costs (1825 records)\n",
            "  âœ“ Created table: safety_metrics_summary (4 records)\n",
            "\n",
            "[BONUS] Creating indexes for query performance...\n",
            "  âœ“ Created index\n",
            "  âœ“ Created index\n",
            "  âœ“ Created index\n",
            "  âœ“ Created index\n",
            "  âœ“ Created index\n",
            "  âœ“ Created index\n",
            "\n",
            "============================================================\n",
            "DATABASE STRUCTURE:\n",
            "============================================================\n",
            "  ðŸ“Š mine_sites: 5 records\n",
            "  ðŸ“Š daily_production: 1,825 records\n",
            "  ðŸ“Š equipment_performance: 8,030 records\n",
            "  ðŸ“Š safety_incidents: 360 records\n",
            "  ðŸ“Š daily_costs: 1,825 records\n",
            "  ðŸ“Š safety_metrics_summary: 4 records\n",
            "\n",
            "============================================================\n",
            "RUNNING TEST QUERIES:\n",
            "============================================================\n",
            "\n",
            "--- Total Production by Site (2025) ---\n",
            "         site_name commodity  total_tonnes  avg_plan_adherence\n",
            "   Iron Ridge Mine  Iron Ore      46935488                93.8\n",
            "Golden Valley Mine      Gold      12099285                93.0\n",
            "Lithium Creek Mine   Lithium        653542                93.2\n",
            " Copper Hills Mine    Copper         18496                92.1\n",
            "\n",
            "--- Equipment Availability by Type ---\n",
            "equipment_type  unit_count  avg_availability  avg_utilization  avg_oee\n",
            "    Haul Truck           8              98.5             85.6     84.2\n",
            "     Excavator           5              98.2             81.8     80.4\n",
            "         Dozer           4              98.3             75.1     73.8\n",
            "    LHD Loader           3              98.1             70.0     68.6\n",
            "   Jumbo Drill           2              98.4             50.4     49.6\n",
            "\n",
            "--- Safety Performance by Site ---\n",
            "         site_name  trifr  ltifr  lti_count  mti_count\n",
            "Golden Valley Mine   1.90   0.38          2          8\n",
            "   Iron Ridge Mine   2.69   0.54          2          8\n",
            "Lithium Creek Mine   5.07   1.01          2          8\n",
            " Copper Hills Mine   8.15   1.63          2          8\n",
            "\n",
            "--- Cost Efficiency by Site ---\n",
            "         site_name commodity  avg_cost_per_unit  total_cost_millions_aud\n",
            "   Iron Ridge Mine  Iron Ore              27.05                  1269.63\n",
            "Golden Valley Mine      Gold            2355.21                   970.96\n",
            "Lithium Creek Mine   Lithium           72323.40                   417.42\n",
            " Copper Hills Mine    Copper              78.76                    75.43\n",
            "\n",
            "============================================================\n",
            "âœ… DATABASE CREATION COMPLETE!\n",
            "============================================================\n",
            "\n",
            "ðŸ“¦ Database file created: mining_operations.db\n",
            "   Size: 1.83 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6TzQPbScxO9s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}